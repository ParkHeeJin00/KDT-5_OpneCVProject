# KDT - 5 OpenCV Project

## 견종 추정 서비스
1. 사진 제출 : 개의 사진을 업로드
2. 견종 추정 : 추출한 외형적 특징을 바탕으로 가장 가능성 있는 견종과 확률 파이차트 제시
3. 추가 정보 : 견종에 대한 더 많은 정보와 특징 제공
  
#### DATA
[https://www.kaggle.com/datasets/msambare/fer2013](https://www.kaggle.com/datasets/amandam1/120-dog-breeds-breed-classification)
  
#### 역할분담

<img width="863" alt="image" src="https://github.com/KDT5-OpenCV/KDT-5_OpneCVProject/assets/155441547/4c8d48f2-d218-4a80-a1bb-fd3f55df6b45">



<details>
  <summary>
    이현길(강아지 크기 분류 모델)
  </summary>

</details>

<details>
  <summary>
    박희진(소형견 견종 분류 모델)
  </summary>

# [ 견종 추정 서비스 ]


## 소형견 분류 모델

## (1) 데이터 확인 및 전처리

- 120종의 강아지 사진 약 20000장
    - 확인해봤더니 강아지 이외의 데이터가 너무 많았음
- 이미지에 노이즈가 너무 많아 노이즈 제거
    - ex) 사람 얼굴
    - 조금 러프하게 제거
- 견종마다 크기 분류를 해주기 위해 각 폴더에 라벨링해줌
    - 소형견 이미지 데이터만 불러와서 앞에 라벨링한 걸 다시 지워줌
- torchvision의 ImageFolder를 이용하여 폴더이름을 라벨로 하여 데이터 로딩
- transforms를 이용하여 데이터를 불러 올 때, 전처리를 해줌
    1. 이미지 데이터의 사진을 (32,32)로 해줌
    2. 텐서화 ( + 0~1의 값으로 정규화 )
- 각 라벨당 이미지 데이터의 수 확인
- 이미지 데이터의 shape와 ndim 확인
- 채널값을 정규화해주기 위해 trainDS의 이미지 데이터로 RGB 평균값과 표준편차 값 도출
    - 데이터셋 내의 모든 이미지에 대해 정규화 진행

## (2) 데이터셋 준비

- 라벨의 비율을 균형적으로 맞춰 학습시켜주기 위해 sklearn의 train_test_split 사용
    - train_test_split 사용하기 위해 불러온 데이터셋에서 이미지와 라벨을 각각 다른 리스트 내에 분리
    - 학습용 데이터와 검증용 데이터는 9 : 1로 분리
- 데이터셋 클래스를 생성 - 최대한 단순하게 클래스 구현
    - 데이터셋 클래스로 trainDS와 validDS 객체 생성

## (3) 데이터 로더 생성

- 배치 내에서도 라벨의 수를 균형적으로 만들어 주기 위해 샘플러 생성
    - 클래스 별 비율을 계산하여 샘플러에 가중치 지정
    - trainDS에만 샘플러를 이용하여 데이터 로더 생성
- batch값은 32으로 지정

## (4) Custom CNN 모델 클래스

- 합성곱층은 총 2개로 구성
    - 이미지 데이터가 색을 가진 이미지 데이터이기 때문에 3채널을 가지고 따라서 첫번째 합성곱층의 입력값은 3임
    - stride를 1로 설정하고 padding도 1로 설정하여 same padding
- 풀링은 최대풀링을 수행하여 특징 맵의 크기를 절반으로 줄이도록 설정
    - ( 32, 32 ) → ( 16, 16 ) → ( 8, 8 )
- 기울기 소실을 방지하고, 학습 속도를 높이면서 학습 과정을 안정화시키기 위해 배치 정규화 시행
    - VGG 모델을 본따, 합성곱층에서만 배치 정규화 시행
    - 모든 층에서 배치정규화를 시행했더니 매우 낮은 성능이 나옴
- 활성화 함수로는 relu 선택
    - leaky_relu와 tahn도 해봤으나 성능에 크게 차이 없었음
- he 가중치 초기화 시행
    - 시간이 제한적인 상황에서 모델 학습과 성능 개선을 더 빠르게 달성하기 위해 사용
    - relu와 he 가중치 초기화 조합이 대체로 좋은 성능을 보여준다고 해서 그 조합으로 선택

## (5) 학습준비 - 학습함수, 평가함수

- 에포크는 1000으로 지정
    - 학습 함수에 스케쥴러를 이용해 조기 종료 기능 구현
    - Valid Loss가 3번 이상 개선이 안되면 조기 종료
- 다중 분류 모델이기 때문에 손실함수로는 CrossEntropyLoss 이용
- 옵티마이저는 Adam 이용
    - 러닝메이트는 0.001로 지정

## (6) Custom CNN 모델 평가

![image](https://github.com/KDT5-OpenCV/KDT-5_OpneCVProject/assets/155441547/1e51bce8-05bf-4022-834f-8247dc449e5c)


- Train Loss : 감소
- Valid Loss : 감소
- Train F1_Score : 증가
- Valid F1_Score : 증가 추세
- 그러나, 증가하는 Loss율을 봤을 때, 에포크가 늘어날 수록 과대적합이 심해질 것이라고 판단됨
- CNN 모델의 은닉층의 개수를 바꾸거나 가중치 초기화를 해주거나 dropout을 해주는 등의 많은 시도를 해봤지만 Valid Score는 0.55가 최대였음
    - 데이터 부족으로 판단하고 다시 전이학습 시행

## (7) 전이학습

- 전이학습 모델로 Resnet18 선택
- 데이터 전처리
    - Resnet18에서 제시하는 RGB 평균값과  표준편차 값에 맞춰 정규화 시행
    - 이미지 데이터 사이즈를 (256,256)으로 하고 늘여지도록 interpolation 설정
    - 위의 데이터와 같이 모델이 균형적인 데이터를 학습하도록 train_test_split을 사용하여 학습용 데이터셋과 검증용 데이터셋을 나눔
    - 마찬가지로 클래스 별 비율을 계산해서 샘플러를 만들어 가중치를 부여하여 각 배치마다 균형적인 데이터가 나오도록 함
    - 배치 사이즈는 32
    

## (8) Resnet18 모델 성능 평가

![image](https://github.com/KDT5-OpenCV/KDT-5_OpneCVProject/assets/155441547/b280e9b1-a6d4-416a-a1d2-80c401ee990f)


- 과대적합이 일어나긴 했지만 test score가 0.81으로 Custom CNN 모델보다 0.3정도 높아졌다. 전이학습은 주로 데이터가 부족할 때 사용하는데, 전이학습을 했을때, 모델 성능이 이정도나 개선된 걸로 봐서는 이전 Custum CNN 모델의 문제점은 부족한 데이터셋이 맞는 것 같다.

## (9) 아쉬운 점

- 총 데이터 수는 2만개지만, 종의 수가 120종이라서 각 종의 데이터는 110~ 150여개에 불과하다. 다중 분류 딥러닝 모델을 학습시키기는 턱없이 적은 데이터임을 모델을 만들고 나서 깨달았다. 이부분을 보강하고자 데이터 전처리도 러프하게 할 것이 아니라 세밀하게 해줬어야 했고, 데이터 증강을 통해 각 종의 부족한 이미지 데이터를 보완해줘야 했다. 누끼 따는 코드를 짜서 뒤늦게 누끼를 땄으나 시간이 부족해서 데이터셋을 완벽히 준비하지 못했고, 그나마 레즈넷 모델을 통해 괜찮은 Score를 볼 수 있었다.
</details>

<details>
  <summary>
    우승연(중형견 견종 분류 모델)
  </summary>

</details>

<details>
  <summary>
    변주영(대형견 견종 분류 모델)
  </summary>
  fsdfsd
</details>

  </summary>

